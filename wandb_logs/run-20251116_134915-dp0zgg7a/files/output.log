/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:483: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(pid=28546)[39m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 2x across cluster]
[36m(pid=28546)[39m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 2x across cluster]
[36m(pid=28546)[39m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 2x across cluster]
[36m(pid=28546)[39m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 2x across cluster]
2025-11-16 13:49:21,776	WARNING util.py:62 -- Install gputil for GPU system monitoring.
======================================================================
Experiment: magnitude_weight_iterative_sparsity25
Technique: magnitude_weight | Schedule: iterative
Target Prune Ratio: 25%
======================================================================
Epoch  1 | Reward:   21.28 | Max:   75.00 | Sparsity:   0.0%
Epoch  2 | Reward:   34.25 | Max:  119.00 | Sparsity:   0.0%
Epoch  3 | Reward:   51.13 | Max:  150.00 | Sparsity:   0.0%
Epoch  4 | Reward:   82.19 | Max:  425.00 | Sparsity:   0.0%
Epoch  5 | Reward:  111.74 | Max:  425.00 | Sparsity:   0.0%
[Epoch 6] Applying pruning (ratio: 0.06)
Epoch  6 | Reward:  142.04 | Max:  500.00 | Sparsity:   6.2%
Epoch  7 | Reward:  177.93 | Max:  500.00 | Sparsity:   6.2%
Epoch  8 | Reward:  210.60 | Max:  500.00 | Sparsity:   6.2%
Epoch  9 | Reward:  245.93 | Max:  500.00 | Sparsity:   6.2%
Epoch 10 | Reward:  278.24 | Max:  500.00 | Sparsity:   6.2%
Epoch 11 | Reward:  312.80 | Max:  500.00 | Sparsity:   6.2%
[Epoch 12] Applying pruning (ratio: 0.12)
Epoch 12 | Reward:  337.79 | Max:  500.00 | Sparsity:  12.5%
Epoch 13 | Reward:  364.44 | Max:  500.00 | Sparsity:  12.5%
Epoch 14 | Reward:  393.16 | Max:  500.00 | Sparsity:  12.5%
Epoch 15 | Reward:  413.26 | Max:  500.00 | Sparsity:  12.5%
Epoch 16 | Reward:  438.22 | Max:  500.00 | Sparsity:  12.5%
Epoch 17 | Reward:  449.81 | Max:  500.00 | Sparsity:  12.5%
[Epoch 18] Applying pruning (ratio: 0.19)
Epoch 18 | Reward:  461.61 | Max:  500.00 | Sparsity:  18.8%
Epoch 19 | Reward:  474.98 | Max:  500.00 | Sparsity:  18.8%
[Epoch 20] Applying pruning (ratio: 0.25)
Epoch 20 | Reward:  485.82 | Max:  500.00 | Sparsity:  25.0%
Epoch 21 | Reward:  489.09 | Max:  500.00 | Sparsity:  25.0%
Epoch 22 | Reward:  493.24 | Max:  500.00 | Sparsity:  25.0%
Epoch 23 | Reward:  497.92 | Max:  500.00 | Sparsity:  25.0%
Epoch 24 | Reward:  497.92 | Max:  500.00 | Sparsity:  25.0%
Epoch 25 | Reward:  499.78 | Max:  500.00 | Sparsity:  25.0%