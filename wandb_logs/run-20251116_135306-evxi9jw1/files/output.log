/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:483: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(pid=28875)[39m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 2x across cluster]
[36m(pid=28875)[39m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 2x across cluster]
[36m(pid=28875)[39m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 2x across cluster]
[36m(pid=28875)[39m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 2x across cluster]
2025-11-16 13:53:13,142	WARNING util.py:62 -- Install gputil for GPU system monitoring.
======================================================================
Experiment: magnitude_weight_iterative_sparsity80
Technique: magnitude_weight | Schedule: iterative
Target Prune Ratio: 80%
======================================================================
Epoch  1 | Reward:   19.60 | Max:   78.00 | Sparsity:   0.0%
Epoch  2 | Reward:   33.99 | Max:   94.00 | Sparsity:   0.0%
Epoch  3 | Reward:   50.96 | Max:  189.00 | Sparsity:   0.0%
Epoch  4 | Reward:   77.98 | Max:  243.00 | Sparsity:   0.0%
Epoch  5 | Reward:  105.99 | Max:  496.00 | Sparsity:   0.0%
[Epoch 6] Applying pruning (ratio: 0.20)
Epoch  6 | Reward:  135.29 | Max:  496.00 | Sparsity:  20.0%
Epoch  7 | Reward:  168.04 | Max:  496.00 | Sparsity:  20.0%
Epoch  8 | Reward:  201.27 | Max:  500.00 | Sparsity:  20.0%
Epoch  9 | Reward:  237.88 | Max:  500.00 | Sparsity:  20.0%
Epoch 10 | Reward:  266.10 | Max:  500.00 | Sparsity:  20.0%
Epoch 11 | Reward:  292.94 | Max:  500.00 | Sparsity:  20.0%
[Epoch 12] Applying pruning (ratio: 0.40)
Epoch 12 | Reward:  321.13 | Max:  500.00 | Sparsity:  40.0%
Epoch 13 | Reward:  333.63 | Max:  500.00 | Sparsity:  40.0%
Epoch 14 | Reward:  333.09 | Max:  500.00 | Sparsity:  40.0%
Epoch 15 | Reward:  318.75 | Max:  500.00 | Sparsity:  40.0%
Epoch 16 | Reward:  259.19 | Max:  500.00 | Sparsity:  40.0%
Epoch 17 | Reward:  189.09 | Max:  337.00 | Sparsity:  40.0%
[Epoch 18] Applying pruning (ratio: 0.60)
Epoch 18 | Reward:  156.45 | Max:  238.00 | Sparsity:  60.0%
Epoch 19 | Reward:  151.11 | Max:  189.00 | Sparsity:  60.0%
[Epoch 20] Applying pruning (ratio: 0.80)
Epoch 20 | Reward:  155.60 | Max:  208.00 | Sparsity:  80.0%
Epoch 21 | Reward:  165.79 | Max:  254.00 | Sparsity:  80.0%
Epoch 22 | Reward:  183.56 | Max:  376.00 | Sparsity:  80.0%
Epoch 23 | Reward:  205.38 | Max:  454.00 | Sparsity:  80.0%
Epoch 24 | Reward:  230.13 | Max:  500.00 | Sparsity:  80.0%
Epoch 25 | Reward:  252.69 | Max:  500.00 | Sparsity:  80.0%