[ASYNC] Epoch   1 | Reward=0.00 | Samples=8000 | Total=4.85s (Rollout=4.20s, Train=0.65s) | Thrpt=1648.6/s | Compile=None
[ASYNC] Epoch   2 | Reward=0.00 | Samples=8000 | Total=5.12s (Rollout=4.30s, Train=0.82s) | Thrpt=1561.3/s | Compile=None
[36m(RolloutWorker pid=66334)[0m W1203 17:22:33.186000 66334 site-packages/torch/utils/cpp_extension.py:118] [0/0] No CUDA runtime is found, using CUDA_HOME='/usr'
[36m(RolloutWorker pid=66334)[0m 2025-12-03 17:22:19,798	WARNING catalog.py:630 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']![32m [repeated 2x across cluster][0m
[36m(RolloutWorker pid=66336)[0m W1203 17:22:34.556000 66336 site-packages/torch/utils/cpp_extension.py:118] [0/0] No CUDA runtime is found, using CUDA_HOME='/usr'
[Broadcast] üì§ Inference backbone updated on all sampler workers.
[AsyncCompile] üîÅ Swapped inference model.
[ASYNC] Epoch   3 | Reward=0.00 | Samples=8000 | Total=5.11s (Rollout=4.40s, Train=0.71s) | Thrpt=1566.1/s | Compile=0.0015437602996826172
[ASYNC] Epoch   4 | Reward=0.00 | Samples=8000 | Total=4.93s (Rollout=4.26s, Train=0.66s) | Thrpt=1623.7/s | Compile=None
[ASYNC] Epoch   5 | Reward=0.00 | Samples=8000 | Total=4.87s (Rollout=4.17s, Train=0.68s) | Thrpt=1643.1/s | Compile=None
[ASYNC] Epoch   6 | Reward=0.00 | Samples=8000 | Total=4.81s (Rollout=4.16s, Train=0.65s) | Thrpt=1664.2/s | Compile=None
[ASYNC] Epoch   7 | Reward=0.00 | Samples=8000 | Total=4.76s (Rollout=4.13s, Train=0.62s) | Thrpt=1681.6/s | Compile=None
[ASYNC] Epoch   8 | Reward=0.00 | Samples=8000 | Total=4.81s (Rollout=4.17s, Train=0.63s) | Thrpt=1664.4/s | Compile=None
[ASYNC] Epoch   9 | Reward=0.00 | Samples=8000 | Total=4.91s (Rollout=4.28s, Train=0.62s) | Thrpt=1629.3/s | Compile=None
[ASYNC] Epoch  10 | Reward=0.00 | Samples=8000 | Total=4.85s (Rollout=4.22s, Train=0.63s) | Thrpt=1649.3/s | Compile=None

=== Summary (async) ===
Epochs: 10
Reward mean (avg over epochs): 0.00
Total time (avg per epoch): 4.90s
  Rollout time avg: 4.23s | Train time avg: 0.67s
Throughput (avg samples/s): 1633.2
Compile latency (avg when available): 0.002s
