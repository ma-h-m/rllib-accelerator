/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:483: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(pid=28772)[39m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 2x across cluster]
[36m(pid=28772)[39m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 2x across cluster]
[36m(pid=28772)[39m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 2x across cluster]
[36m(pid=28772)[39m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 2x across cluster]
2025-11-16 13:52:14,852	WARNING util.py:62 -- Install gputil for GPU system monitoring.
======================================================================
Experiment: magnitude_weight_iterative_sparsity75
Technique: magnitude_weight | Schedule: iterative
Target Prune Ratio: 75%
======================================================================
Epoch  1 | Reward:   19.51 | Max:   50.00 | Sparsity:   0.0%
Epoch  2 | Reward:   31.66 | Max:  168.00 | Sparsity:   0.0%
Epoch  3 | Reward:   46.81 | Max:  130.00 | Sparsity:   0.0%
Epoch  4 | Reward:   66.38 | Max:  222.00 | Sparsity:   0.0%
Epoch  5 | Reward:   94.43 | Max:  449.00 | Sparsity:   0.0%
[Epoch 6] Applying pruning (ratio: 0.19)
Epoch  6 | Reward:  126.45 | Max:  500.00 | Sparsity:  18.8%
Epoch  7 | Reward:  158.31 | Max:  500.00 | Sparsity:  18.8%
Epoch  8 | Reward:  192.09 | Max:  500.00 | Sparsity:  18.8%
Epoch  9 | Reward:  215.93 | Max:  500.00 | Sparsity:  18.8%
Epoch 10 | Reward:  248.89 | Max:  500.00 | Sparsity:  18.8%
Epoch 11 | Reward:  275.83 | Max:  500.00 | Sparsity:  18.8%
[Epoch 12] Applying pruning (ratio: 0.38)
Epoch 12 | Reward:  303.73 | Max:  500.00 | Sparsity:  37.5%
Epoch 13 | Reward:  312.78 | Max:  500.00 | Sparsity:  37.5%
Epoch 14 | Reward:  300.70 | Max:  500.00 | Sparsity:  37.5%
Epoch 15 | Reward:  273.44 | Max:  500.00 | Sparsity:  37.5%
Epoch 16 | Reward:  258.15 | Max:  500.00 | Sparsity:  37.5%
Epoch 17 | Reward:  256.11 | Max:  500.00 | Sparsity:  37.5%
[Epoch 18] Applying pruning (ratio: 0.56)
Epoch 18 | Reward:  266.45 | Max:  500.00 | Sparsity:  56.2%
Epoch 19 | Reward:  266.17 | Max:  500.00 | Sparsity:  56.2%
[Epoch 20] Applying pruning (ratio: 0.75)
Epoch 20 | Reward:  271.09 | Max:  500.00 | Sparsity:  75.0%
Epoch 21 | Reward:  259.78 | Max:  500.00 | Sparsity:  75.0%
Epoch 22 | Reward:  128.57 | Max:  346.00 | Sparsity:  75.0%
Epoch 23 | Reward:   18.84 | Max:  100.00 | Sparsity:  75.0%
Epoch 24 | Reward:   14.07 | Max:   22.00 | Sparsity:  75.0%
Epoch 25 | Reward:   12.06 | Max:   16.00 | Sparsity:  75.0%