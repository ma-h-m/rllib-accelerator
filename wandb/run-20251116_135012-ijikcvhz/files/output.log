/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:483: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(pid=28612)[39m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 2x across cluster]
[36m(pid=28612)[39m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 2x across cluster]
[36m(pid=28612)[39m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 2x across cluster]
[36m(pid=28612)[39m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 2x across cluster]
2025-11-16 13:50:18,792	WARNING util.py:62 -- Install gputil for GPU system monitoring.
======================================================================
Experiment: magnitude_weight_iterative_sparsity50
Technique: magnitude_weight | Schedule: iterative
Target Prune Ratio: 50%
======================================================================
Epoch  1 | Reward:   24.30 | Max:   68.00 | Sparsity:   0.0%
Epoch  2 | Reward:   38.83 | Max:  121.00 | Sparsity:   0.0%
Epoch  3 | Reward:   54.40 | Max:  134.00 | Sparsity:   0.0%
Epoch  4 | Reward:   82.24 | Max:  246.00 | Sparsity:   0.0%
Epoch  5 | Reward:  111.13 | Max:  415.00 | Sparsity:   0.0%
[Epoch 6] Applying pruning (ratio: 0.12)
Epoch  6 | Reward:  141.17 | Max:  500.00 | Sparsity:  12.5%
Epoch  7 | Reward:  178.36 | Max:  500.00 | Sparsity:  12.5%
Epoch  8 | Reward:  210.72 | Max:  500.00 | Sparsity:  12.5%
Epoch  9 | Reward:  243.17 | Max:  500.00 | Sparsity:  12.5%
Epoch 10 | Reward:  278.43 | Max:  500.00 | Sparsity:  12.5%
Epoch 11 | Reward:  310.50 | Max:  500.00 | Sparsity:  12.5%
[Epoch 12] Applying pruning (ratio: 0.25)
Epoch 12 | Reward:  335.22 | Max:  500.00 | Sparsity:  25.0%
Epoch 13 | Reward:  364.81 | Max:  500.00 | Sparsity:  25.0%
Epoch 14 | Reward:  393.59 | Max:  500.00 | Sparsity:  25.0%
Epoch 15 | Reward:  413.64 | Max:  500.00 | Sparsity:  25.0%
Epoch 16 | Reward:  437.15 | Max:  500.00 | Sparsity:  25.0%
Epoch 17 | Reward:  452.89 | Max:  500.00 | Sparsity:  25.0%
[Epoch 18] Applying pruning (ratio: 0.38)
Epoch 18 | Reward:  465.85 | Max:  500.00 | Sparsity:  37.5%
Epoch 19 | Reward:  460.48 | Max:  500.00 | Sparsity:  37.5%
[Epoch 20] Applying pruning (ratio: 0.50)
Epoch 20 | Reward:  437.77 | Max:  500.00 | Sparsity:  50.0%
Epoch 21 | Reward:  381.08 | Max:  500.00 | Sparsity:  50.0%
Epoch 22 | Reward:  315.32 | Max:  500.00 | Sparsity:  50.0%
Epoch 23 | Reward:  250.07 | Max:  500.00 | Sparsity:  50.0%
Epoch 24 | Reward:  204.11 | Max:  338.00 | Sparsity:  50.0%
Epoch 25 | Reward:  194.45 | Max:  281.00 | Sparsity:  50.0%