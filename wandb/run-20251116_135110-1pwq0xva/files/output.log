/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:483: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/opt/anaconda3/envs/rllib-env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(pid=28703)[39m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 2x across cluster]
[36m(pid=28703)[39m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 2x across cluster]
[36m(pid=28703)[39m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 2x across cluster]
[36m(pid=28703)[39m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 2x across cluster]
2025-11-16 13:51:16,775	WARNING util.py:62 -- Install gputil for GPU system monitoring.
======================================================================
Experiment: magnitude_weight_iterative_sparsity60
Technique: magnitude_weight | Schedule: iterative
Target Prune Ratio: 60%
======================================================================
Epoch  1 | Reward:   22.04 | Max:   85.00 | Sparsity:   0.0%
Epoch  2 | Reward:   34.41 | Max:  110.00 | Sparsity:   0.0%
Epoch  3 | Reward:   56.88 | Max:  212.00 | Sparsity:   0.0%
Epoch  4 | Reward:   86.18 | Max:  321.00 | Sparsity:   0.0%
Epoch  5 | Reward:  117.73 | Max:  343.00 | Sparsity:   0.0%
[Epoch 6] Applying pruning (ratio: 0.15)
Epoch  6 | Reward:  148.72 | Max:  500.00 | Sparsity:  15.0%
Epoch  7 | Reward:  178.15 | Max:  500.00 | Sparsity:  15.0%
Epoch  8 | Reward:  210.02 | Max:  500.00 | Sparsity:  15.0%
Epoch  9 | Reward:  240.84 | Max:  500.00 | Sparsity:  15.0%
Epoch 10 | Reward:  271.37 | Max:  500.00 | Sparsity:  15.0%
Epoch 11 | Reward:  297.79 | Max:  500.00 | Sparsity:  15.0%
[Epoch 12] Applying pruning (ratio: 0.30)
Epoch 12 | Reward:  326.31 | Max:  500.00 | Sparsity:  30.0%
Epoch 13 | Reward:  354.26 | Max:  500.00 | Sparsity:  30.0%
Epoch 14 | Reward:  380.79 | Max:  500.00 | Sparsity:  30.0%
Epoch 15 | Reward:  405.60 | Max:  500.00 | Sparsity:  30.0%
Epoch 16 | Reward:  422.33 | Max:  500.00 | Sparsity:  30.0%
Epoch 17 | Reward:  437.97 | Max:  500.00 | Sparsity:  30.0%
[Epoch 18] Applying pruning (ratio: 0.45)
Epoch 18 | Reward:  447.59 | Max:  500.00 | Sparsity:  45.0%
Epoch 19 | Reward:  458.82 | Max:  500.00 | Sparsity:  45.0%
[Epoch 20] Applying pruning (ratio: 0.60)
Epoch 20 | Reward:  469.51 | Max:  500.00 | Sparsity:  60.0%
Epoch 21 | Reward:  476.23 | Max:  500.00 | Sparsity:  60.0%
Epoch 22 | Reward:  484.27 | Max:  500.00 | Sparsity:  60.0%
Epoch 23 | Reward:  491.06 | Max:  500.00 | Sparsity:  60.0%
Epoch 24 | Reward:  490.67 | Max:  500.00 | Sparsity:  60.0%
Epoch 25 | Reward:  482.31 | Max:  500.00 | Sparsity:  60.0%